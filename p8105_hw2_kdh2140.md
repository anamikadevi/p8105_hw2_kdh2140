Data Science Homework 2
================
Kristina Howell

The following libraries will be used throughout the homework.

``` r
library(readxl)
library(tidyverse)
```

## Problem 1

Read and clean the Mr. Trash Wheel sheet according to homework
specifications.

``` r
trash_wheel = read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                         sheet = "Mr. Trash Wheel", range = "A2:N408") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = round(sports_balls), 
         sports_balls = as.integer(sports_balls))

#Another range argument: range = cell_cols("A:N")
```

Read and clean the precipitation data for 2018 and 2017 according to
homework.

``` r
prec_18 = read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                         sheet = "2018 Precipitation", range = "A2:B15") %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  rename(prec = total) %>% 
  mutate(year = 2018) %>% 
  relocate(year)
  
  #alternate argument, skip = 1, to skip the first row of table
  
prec_17 = read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                         sheet = "2017 Precipitation", range = "A2:B15") %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  rename(prec = total) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Merge the two datasets

``` r
precip_df = bind_rows(prec_18, prec_17)
```

The Mr. Trash Wheel dataset consists of 344 rows and 14 columns. It
includes the variables: dumpster, month, year, date, weight\_tons,
volume\_cubic\_yards, plastic\_bottles, polystyrene, cigarette\_butts,
glass\_bottles, grocery\_bags, chip\_bags, sports\_balls,
homes\_powered. The median number of sports balls in a dumpster in 2017
is 8 .

## Problem 2

Read and clean the NYC transit data according to homework
specifications.

``` r
nyc_transit = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, route1:route11, 
         entry, entrance_type, vending, ada) %>% 
  mutate(ada = as.logical(ada))
```

The nyc\_transit dataset offers general but comprehensive information
about the transit stations located in NYC. It contains the variables:
line, station\_name, station\_latitude, station\_longitude, route1,
route2, route3, route4, route5, route6, route7, route8, route9, route10,
route11, entry, entrance\_type, vending, ada. Overall, the dataset has
1868 rows and 19 columns.

The data cleaning steps have included cleaning the names, using the
clean\_names() function, selecting the variables to keep in the data
set, using the select() function, and converting the ada character
variable to a logical variable using the mutate() function.

The data is mostly tidy, but the columns regarding route number could be
improved.

#### Problem 2 Questions

###### How many distinct stations are there?

Regarding the distinctions between line and station name, there are 465
distinct stations within the data set.

###### How many stations are ADA compliant?

There are 84 distinct stations that are ADA compliant.

###### What proportion of station entrances / exits without vending allow entrance?

There are 43 distinct stations that allow exit/ entry without vending.

##### Reformat data so that route number and route name are distinct variables.

This code chunk will utilize the pivot\_longer function to reformat the
route number and route names into distinct variables. Extraneous
variables and observations are dropped from the dataset.

``` r
nyc_transit = mutate(nyc_transit, route8 = as.character(route8),
       route9 = as.character(route9),
       route10 = as.character(route10),
       route11 = as.character(route11)) %>% 
pivot_longer(
    route1:route11,
    values_to = "route") %>% 
  select(-name) %>% 
  drop_na(route)

#Note: is there a more streamlined function to mutate several variables at once?
  #i.e. route8:route11 = as.character?
```

###### How many distinct stations serve the A train?

There are 60 distinct stations that serve the A train.

###### Of the stations that serve the A train, how many are ADA compliant?

There are 17 distinct stations that serve the A train and are ADA
compliant.

## Problem 3

##### Import the data sets

Each dataset is imported using the read\_csv function in the tidyverse
library. Month variables are mutated so that they can be easily merged
to the tibble created in the subsequent dataset. Data cleaning is
performed for each dataset as needed, including the reformatting of the
president and unemployment variable. Extraneous variables are removed.

``` r
pols_month = read_csv("./Data/fivethirtyeight_datasets/pols-month.csv") %>% 
  separate(mon, c("year", "month", "day")) %>% 
  mutate(month = as.integer(month),
         year = as.integer(year)) %>% 
  relocate(prez_gop, prez_dem) %>% 
  pivot_longer(
    prez_gop:prez_dem,
    names_prefix = "prez_",
    names_to = "president"
  ) %>%
  filter(value == 1) %>% 
  select(-day, -value) %>% 
  relocate(year, month, president)
  
#Month is reformatted correctly in the following code chunk. 
  
snp = read_csv("./Data/fivethirtyeight_datasets/snp.csv") %>% 
    separate(date, c("month", "day", "year")) %>% 
    select(-day) %>% 
    relocate(year, month) %>% 
    mutate(month = as.integer(month),
           year = as.integer(year))


unemploy = read_csv("./Data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment"
  ) %>% 
  mutate(year = as.integer(year))
```

##### Convert integer month to word month

The month variables are formatted differently in each dataset. This code
chunk uses a tibble to left merge into the datasets by the key, “month”.
This ensures that all datasets have an identical month key for the merge
in the subsequent code chunk.

``` r
month_df = 
  tibble( 
    month = 1:12,
    month_name = month.abb)

pols_month = left_join(pols_month, month_df, by = "month") %>% 
  select(-month) %>% 
  rename(month = month_name) %>% 
  relocate(year, month) %>% 
  mutate(month = str_to_lower(month))

snp = left_join(snp, month_df, by = "month") %>% 
  select(-month) %>% 
  rename(month = month_name) %>% 
  relocate(year, month) %>% 
  mutate(month = str_to_lower(month))
```

##### Merge datasets by keys: year and month

This will ensure that the datasets are accurately matched in time. The
left join adds snp to pols\_month and then adds unemploy to that
dataset.

``` r
j_poli_df = left_join(pols_month, snp, by = c("year", "month")) %>% 
  left_join(unemploy, by = c("year", "month"))
```

##### Dataset Description

Each dataset contained unique information about the political and
economic status of the country by year and month. The dataset,
**pols\_month**, included information about breakdown of poliical party
status per government position by month and year, beginning in January
1947. The dataset, **snp**, refers to the S\&P stock index and reports
the closing value by month dating to 1950. The dataset, **unemploy**,
contains the percentage of unemployed individuals by month dating to
1948.

The resulting merged dataset, **j\_poli\_df**, contains this information
in a tidy manner compared to the original files. The dataset contains
817 rows and 11 columns. Key variables include *“president”* which lists
the political party status of the president, *“closing”* which reports
the closing value of the S\&P by month, and *“unemploy”* which states
the unemployment percentage by month. These variables range in time from
1947 to 2015.
