---
title: "Data Science Homework 2"
author: Kristina Howell
output: github_document
---

The following libraries will be used throughout the homework. 

```{r load_libraries, message = FALSE}
library(readxl)
library(tidyverse)
```


## Problem 1

Read and clean the Mr. Trash Wheel sheet according to homework specifications. 

```{r trash_wheel_dataset}
trash_wheel = read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                         sheet = "Mr. Trash Wheel", range = "A2:N408") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = round(sports_balls), 
         sports_balls = as.integer(sports_balls))

#Another range argument: range = cell_cols("A:N")
```

Read and clean the precipitation data for 2018 and 2017 according to homework.

```{r precipitation_datasets}
prec_18 = read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                         sheet = "2018 Precipitation", range = "A2:B15") %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  rename(prec = total) %>% 
  mutate(year = 2018) %>% 
  relocate(year)
  
  #alternate argument, skip = 1, to skip the first row of table
  
prec_17 = read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                         sheet = "2017 Precipitation", range = "A2:B15") %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  rename(prec = total) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Merge the two datasets

```{r binding_datasets}

precip_df = bind_rows(prec_18, prec_17)

```


The Mr. Trash Wheel dataset consists of `r nrow(trash_wheel)` rows and `r ncol(trash_wheel)` columns. It includes the variables: `r names(trash_wheel)`. The median number of sports balls in a dumpster in 2017 is `r median(trash_wheel$sports_balls)` .

## Problem 2

Read and clean the NYC transit data according to homework specifications.

```{r NYC_transit_dataset, message = FALSE}
nyc_transit = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, route1:route11, 
         entry, entrance_type, vending, ada) %>% 
  mutate(ada = as.logical(ada))
```

The nyc_transit dataset offers general but comprehensive information about the transit stations located in NYC. It contains the variables: `r names(nyc_transit)`. Overall, the dataset has `r nrow(nyc_transit)` rows and `r ncol(nyc_transit)` columns. 

The data cleaning steps have included cleaning the names, using the clean_names() function, selecting the variables to keep in the data set, using the select() function, and converting the ada character variable to a logical variable using the mutate() function. 

The data is mostly tidy, but the columns regarding route number could be improved. 

#### Problem 2 Questions

###### How many distinct stations are there? 

Regarding the distinctions between line and station name, there are `r nrow(distinct(nyc_transit, line, station_name))` distinct stations within the data set.

###### How many stations are ADA compliant?

There are `r nyc_transit %>% filter(ada == "TRUE") %>% distinct(station_name, line) %>% nrow()` distinct stations that are ADA compliant.

###### What proportion of station entrances / exits without vending allow entrance?

There are `r nyc_transit %>% filter(vending == "NO", entry == "YES") %>% distinct(station_name, line) %>% nrow()` distinct stations that allow exit/ entry without vending.

##### Reformat data so that route number and route name are distinct variables.
This code chunk will utilize the pivot_longer function to reformat the route number and route names into distinct variables. Extraneous variables and observations are dropped from the dataset.

```{r distinct_variables}
nyc_transit = mutate(nyc_transit, route8 = as.character(route8),
       route9 = as.character(route9),
       route10 = as.character(route10),
       route11 = as.character(route11)) %>% 
pivot_longer(
    route1:route11,
    values_to = "route") %>% 
  select(-name) %>% 
  drop_na(route)

#Note: is there a more streamlined function to mutate several variables at once?
  #i.e. route8:route11 = as.character?
```

###### How many distinct stations serve the A train? 

There are `r nyc_transit %>% filter(route == "A") %>% distinct(station_name, line) %>% nrow()` distinct stations that serve the A train.

###### Of the stations that serve the A train, how many are ADA compliant?

There are `r nyc_transit %>% filter(route == "A", ada == "TRUE") %>% distinct(station_name, line) %>% nrow()` distinct stations that serve the A train and are ADA compliant.

## Problem 3

##### Import the data sets
Each dataset is imported using the read_csv function in the tidyverse library. Month variables are mutated so that they can be easily merged to the tibble created in the subsequent dataset. Data cleaning is performed for each dataset as needed, including the reformatting of the president and unemployment variable. Extraneous variables are removed.

```{r import_data, message = FALSE}

pols_month = read_csv("./Data/fivethirtyeight_datasets/pols-month.csv") %>% 
  separate(mon, c("year", "month", "day")) %>% 
  mutate(month = as.integer(month),
         year = as.integer(year)) %>% 
  relocate(prez_gop, prez_dem) %>% 
  pivot_longer(
    prez_gop:prez_dem,
    names_prefix = "prez_",
    names_to = "president"
  ) %>%
  filter(value == 1) %>% 
  select(-day, -value) %>% 
  relocate(year, month, president)
  
#Month is reformatted correctly in the following code chunk. 
  
snp = read_csv("./Data/fivethirtyeight_datasets/snp.csv") %>% 
    separate(date, c("month", "day", "year")) %>% 
    select(-day) %>% 
    relocate(year, month) %>% 
    mutate(month = as.integer(month),
           year = as.integer(year))


unemploy = read_csv("./Data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment"
  ) %>% 
  mutate(year = as.integer(year))
```


##### Convert integer month to word month
The month variables are formatted differently in each dataset. This code chunk uses a tibble to left merge into the datasets by the key, "month". This ensures that all datasets have an identical month key for the merge in the subsequent code chunk.

```{r month}

month_df = 
  tibble( 
    month = 1:12,
    month_name = month.abb)

pols_month = left_join(pols_month, month_df, by = "month") %>% 
  select(-month) %>% 
  rename(month = month_name) %>% 
  relocate(year, month) %>% 
  mutate(month = str_to_lower(month))

snp = left_join(snp, month_df, by = "month") %>% 
  select(-month) %>% 
  rename(month = month_name) %>% 
  relocate(year, month) %>% 
  mutate(month = str_to_lower(month))

```


##### Merge datasets by keys: year and month
This will ensure that the datasets are accurately matched in time.  The left join adds snp to pols_month and then adds unemploy to that dataset. 

```{r merge_three}

j_poli_df = left_join(pols_month, snp, by = c("year", "month")) %>% 
  left_join(unemploy, by = c("year", "month"))
 
```

##### Dataset Description

Each dataset contained unique information about the political and economic status of the country by year and month. The dataset, **pols_month**, included information about breakdown of poliical party status per government position by month and year, beginning in January 1947. The dataset, **snp**, refers to the S&P stock index and reports the closing value by month dating to 1950. The dataset, **unemploy**, contains the percentage of unemployed individuals by month dating to 1948. 

The resulting merged dataset, **j_poli_df**, contains this information in a tidy manner compared to the original files. The dataset contains `r nrow(j_poli_df)` rows and `r ncol(j_poli_df)` columns. Key variables include _"president"_ which lists the political party status of the president, _"closing"_ which reports the closing value of the S&P by month, and _"unemploy"_ which states the unemployment percentage by month. These variables range in time from 1947 to 2015.  


